در یادگیری ماشین و به خصوص در مدل‌های زبانی بزرگ (LLMs) مانند **BERT**، **T5**، **GPT** و غیره، فرآیند تنظیم (fine-tuning) نقش مهمی در انتقال دانش عمومی موجود در مدل به یک وظیفه خاص بازی می‌کند. در ادامه انواع روش‌های tuning را بر اساس **کارایی پارامتری (Parameter Efficient Fine-Tuning)** و همچنین **روش‌های سنتی fine-tuning** مقایسه می‌کنیم.

---

## ✅ انواع Tuning

### 1. **Fine-tuning کلاسیک (Full Parameter Fine-tuning)**

- **توضیح:** تمام پارامترهای مدل اصلی به‌روزرسانی می‌شوند.
- **کاربرد:** زمانی استفاده می‌شود که منابع محاسباتی زیادی وجود داشته باشد.
- **مزایا:**
  - عملکرد بالا روی وظایف مختلف
  - بهترین نتایج در شرایط **داده‌های فراوان**
- **معایب:**
  - هزینه‌ی بالای ذخیره‌سازی و محاسباتی
  - هر وظیفه نیازمند یک کپی مستقل از مدل است
  - عدم انعطاف‌پذیری در شرایط کمبود داده

---

### 2. **Prompt-based Tuning (Zero-shot / Few-shot)**

- **توضیح:** بدون تغییر وزن‌ها، از طریق اضافه کردن **prompt template** و تطبیق آن با کلمات خروجی (verbalizer)، مدل را برای وظیفه جدید آموزش می‌دهند.
- **انواع:**
  - **Zero-shot Prompt Tuning**: بدون داده‌های آموزشی، فقط با prompt.
  - **Few-shot Prompt Tuning**: با تعداد کمی داده (مثلاً 10 نمونه).
- **مزایا:**
  - نیاز کم به داده
  - بدون تغییر پارامترهای اصلی مدل (بدون backprop)
  - قابلیت انتقال به وظایف جدید بدون re-training
- **معایب:**
  - وابستگی به طراحی دقیق prompt و verbalizer
  - حساس به انتخاب کلمات خروجی (label words)
  - عملکرد پایین‌تر در شرایط داده‌های فراوان

---

### 3. **Adapter Tuning**

- **توضیح:** در این روش، فقط لایه‌های کوچکی (adapters) به مدل اضافه می‌شوند و فقط این لایه‌ها به‌روزرسانی می‌شوند.
- **مزایا:**
  - تعداد پارامترهای قابل تنظیم بسیار کم (معمولاً < 1% از کل مدل)
  - ذخیره‌سازی کارآمد: فقط adapterها ذخیره می‌شوند
  - قابلیت استفاده مشترک از adapterها برای چندین وظیفه (multi-task)
- **معایب:**
  - کاهش کمی عملکرد نسبت به full fine-tuning
  - افزایش زمان پردازش (به دلیل لایه‌های اضافه)

---

### 4. **Prefix Tuning**

- **توضیح:** در این روش، **prefix vector** ثابتی به عنوان context اضافی به ورودی مدل داده می‌شود. این prefix در طول training به‌روزرسانی می‌شود ولی مدل اصلی ثابت می‌ماند.
- **مزایا:**
  - تعداد پارامترهای قابل تنظیم بسیار کم
  - بدون تغییر معماری اصلی مدل
  - مناسب برای شرایط کم‌داده
- **معایب:**
  - نیاز به تنظیم طول prefix
  - محدودیت در مدل‌های encoder-decoder (مثل T5)
  - کاهش فضای context به دلیل استفاده از prefix

---

### 5. **LoRA (Low-Rank Adaptation)**

- **توضیح:** این روش با اضافه کردن یک ماتریس کم‌رانک (low-rank matrix) به وزن‌های اصلی، تنظیم مدل را انجام می‌دهد.
- **مزایا:**
  - تعداد پارامترهای قابل تنظیم بسیار کم (معمولاً r=1 تا 64)
  - بدون تغییر معماری اصلی مدل
  - سازگار با تمام انواع attention
  - قابلیت استفاده در تمام لایه‌های Transformer
- **معایب:**
  - نیاز به پیاده‌سازی مخصوص
  - ممکن است در برخی وظایف با کاهش عملکرد مواجه شود

---

### 6. **IA³ (Infused Adapter by Inhibition and Amplification)**

- **توضیح:** شبیه به LoRA، اما به جای اضافه کردن، وزن‌ها را با ضرایب اسکالر تقویت یا تضعیف می‌کند.
- **مزایا:**
  - بسیار کم‌هزینه (تنها چند هزار پارامتر)
  - بدون تغییر معماری اصلی
- **معایب:**
  - عملکرد کمتر از LoRA و Adapter
  - محدودیت در نحوه تطبیق با وظایف مختلف

---

## 📊 مقایسه کلی

| نوع Tuning             | تعداد پارامتر قابل تنظیم | دقت (نسبت به Full FT) | مناسب برای | ملاحظات |
|------------------------|----------------------------|--------------------------|--------------|------------|
| **Full Fine-tuning**   | 100%                       | بالا                     | داده فراوان    | هزینه‌بر، ذخیره‌سازی سنگین |
| **Prompt Tuning**      | 0%                         | متوسط                   | داده کم       | نیاز به طراحی دقیق prompt |
| **Adapter Tuning**     | <1%                        | متوسط تا بالا            | چند وظیفه     | کاهش سرعت، افزایش memory |
| **Prefix Tuning**      | <1%                        | متوسط                   | زبان‌های طبیعی | کاهش context length |
| **LoRA**               | <1%                        | بالا                     | تمام وظایف    | سازگار با attention |
| **IA³**                | 0.01%                      | پایین                   | منابع محدود   | دقت پایین |

---

## 🔍 مقایسه عملکردی (با توجه به فایل‌ها)

| روش                  | SST-2 (acc) | SNLI (acc) | CoLA (acc) | QNLI (acc) | منبع |
|-----------------------|-------------|------------|------------|------------|--------|
| **Prompt-based zero-shot** | 83.6        | 49.5       | 32.0       | 50.8       | Zero-Shot File |
| **Prompt-based few-shot**  | 92.7        | 77.2       | 91.2       | 64.5       | Zero-Shot File |
| **Full Fine-tuning**       | 95.0        | 92.6       | 97.0       | 93.3       | Zero-Shot File |
| **Adapter Tuning**         | 92.3        | 76.6       | 91.4       | 68.3       | PEFT File |
| **LoRA**                   | 91.8        | 75.4       | 90.7       | 67.9       | PEFT File |
| **Prefix Tuning**          | 90.2        | 74.1       | 89.5       | 65.4       | PEFT File |

---

## 🧠 نتیجه‌گیری

| شرایط              | بهترین روش Tuning        |
|---------------------|---------------------------|
| **منابع محاسباتی زیاد + داده فراوان** | Full Fine-tuning |
| **داده کم (<100 نمونه)**           | Prompt-based + Few-shot |
| **نیاز به ذخیره‌سازی کارآمد**       | Adapter / LoRA |
| **استفاده از یک مدل برای چندین وظیفه** | Adapter Fusion / LoRA |
| **عدم دستکاری پارامترهای اصلی**     | Prompt Tuning / Prefix Tuning |
| **حداقل پارامتر قابل تنظیم**         | IA³ / LoRA (r=1) |

---

### 🎯 پیشنهاد نهایی:

- اگر منابع کافی دارید و دقت بالا مهم است: **Full Fine-tuning**
- اگر منابع محدود است و دقت نسبتاً بالا مطلوب است: **LoRA یا Adapter Tuning**
- اگر داده بسیار کم دارید و می‌خواهید بدون تغییر مدل کار کنید: **Prompt-based Few-shot Tuning**
- اگر می‌خواهید چندین وظیفه را با یک مدل مدیریت کنید: **Adapter Fusion یا LoRA**

---

اگر به صورت **عملی** قصد پیاده‌سازی دارید:
- برای **سرعت** و **کارایی**: LoRA (با HuggingFace PEFT library)
- برای **انعطاف‌پذیری**: Prompt-based Tuning (با موتور جستجوی خودکار الگوها مثل LM-BFF)
- برای **مدیریت چند وظیفه**: Adapter Hub (با استفاده از TensorFlow/PyTorch)

---

اگر می‌خواهید برای یک **زبان کم‌منبع** (Low-resource Language) مثل فارسی اقدام کنید:
- استفاده از **Prompt-based Few-shot** با الگوهای خودکار
- استفاده از **LoRA** روی مدل‌های multilingual مانند mBERT یا XLM-R
- استفاده از **Adapter Tuning** با مدل‌های موجود در [AdapterHub](https://adapterhub.ml/) برای زبان‌های مشابه

---

### منابع:
- `section6-parameter efficient fine tuning.pdf`
- `section5-zero-shot learning.pdf`
- `section4-Transformers (part3).pdf`

اگر مثال کاربردی یا کد اجرایی از یکی از این روش‌ها را می‌خواهید، بفرمایید!

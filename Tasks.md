### âœ… **Ø§Ù†ÙˆØ§Ø¹ ÙˆØ¸Ø§ÛŒÙ (Tasks) Ú©Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø¨Ø²Ø±Ú¯ (LLMs) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ù†Ø¯**

Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…Ø§Ù†Ù†Ø¯ **BERTØŒ T5ØŒ GPTØŒ BART** Ùˆ ØºÛŒØ±Ù‡ Ù‚Ø§Ø¯Ø± Ø¨Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙÛŒ Ø§Ø² ÙˆØ¸Ø§ÛŒÙ Ø¯Ø± Ø­ÙˆØ²Ù‡ **Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ (NLP)** Ù‡Ø³ØªÙ†Ø¯. Ø§ÛŒÙ† ÙˆØ¸Ø§ÛŒÙ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø®Ø±ÙˆØ¬ÛŒØŒ Ø³Ø§Ø®ØªØ§Ø± ÙˆØ±ÙˆØ¯ÛŒ ÛŒØ§ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ØªÙ‚Ø³ÛŒÙ… Ú©Ø±Ø¯.

---

## ğŸ“Œ **Û±. Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¸Ø§ÛŒÙ NLP**

### Ø§Ù„Ù) **Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡**
| Ù†ÙˆØ¹ | ØªÙˆØ¶ÛŒØ­ |
|------|--------|
| **Token-level tasks** | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ù‡Ø± ØªÙˆÚ©Ù† (Ú©Ù„Ù…Ù‡/Ø²ÛŒØ±Ú©Ù„Ù…Ù‡) Ù…Ø§Ù†Ù†Ø¯ NERØŒ POS Tagging |
| **Sentence-level tasks** | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù„ Ø¬Ù…Ù„Ù‡ ÛŒØ§ ÛŒÚ© Ø¨Ø®Ø´ Ø§Ø² Ø¢Ù† Ù…Ø§Ù†Ù†Ø¯ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¬Ù…Ù„Ù‡ |
| **Sentence-pair tasks** | Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ Ù…Ø§Ù†Ù†Ø¯ Natural Language InferenceØŒ Paraphrase Detection |
| **Sequence-to-sequence tasks** | ØªØ¨Ø¯ÛŒÙ„ ÛŒÚ© Ù…ØªÙ† Ø¨Ù‡ Ù…ØªÙ† Ø¯ÛŒÚ¯Ø± Ù…Ø§Ù†Ù†Ø¯ ØªØ±Ø¬Ù…Ù‡ØŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ |

---

### Ø¨) **Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø®Ø±ÙˆØ¬ÛŒ**
| Ù†ÙˆØ¹ | ØªÙˆØ¶ÛŒØ­ | Ù…Ø«Ø§Ù„ |
|------|--------|-------|
| **Classification** | Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¬Ù…Ù„Ù‡ ÛŒØ§ ØªÙˆÚ©Ù† | Sentiment AnalysisØŒ NER |
| **Regression** | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¹Ø¯Ø¯ÛŒ | Ø´Ø¨Ø§Ù‡Øª Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ (STS-B) |
| **Text Generation** | ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† | ØªØ±Ø¬Ù…Ù‡ØŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ù‡ Ø³Ø¤Ø§Ù„ |
| **Span Prediction** | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚Ø³Ù…ØªÛŒ Ø§Ø² Ù…ØªÙ† | Question Answering (SQuAD) |
| **Multiple Choice** | Ø§Ù†ØªØ®Ø§Ø¨ Ú¯Ø²ÛŒÙ†Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø² Ú†Ù†Ø¯ Ú¯Ø²ÛŒÙ†Ù‡ | SWAGØŒ HellaSwag |

---

### Ø¬) **Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù…Ø¯Ù„**
| Ù…Ø¯Ù„ | ÙˆØ¸Ø§ÛŒÙ Ù…Ù†Ø§Ø³Ø¨ |
|------|------------------|
| **Encoder-only (BERT)** | ClassificationØŒ NERØŒ QA |
| **Decoder-only (GPT)** | Text GenerationØŒ Completion |
| **Encoder-Decoder (T5, BART)** | TranslationØŒ SummarizationØŒ QAØŒ Rewriting |

---

## ğŸ§  **Û². ÙˆØ¸Ø§ÛŒÙ Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ùˆ Ù…Ø¹Ø±ÙˆÙ Ø¯Ø± Ø­ÙˆØ²Ù‡ NLP**

### ğŸ”¹ **Ø§Ù„Ù) Sentence-level Tasks**
#### 1. **Sentiment Analysis (SA)**
- **ØªÙˆØ¶ÛŒØ­:** ØªØ´Ø®ÛŒØµ Ù†Ø¸Ø± Ù…Ø«Ø¨Øª/Ù…Ù†ÙÛŒ/Ø®Ù†Ø«ÛŒ
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: This movie was terrible.
  Output: negative
  ```

#### 2. **Natural Language Inference (NLI)**
- **ØªÙˆØ¶ÛŒØ­:** ØªØ¹ÛŒÛŒÙ† Ø±Ø§Ø¨Ø·Ù‡ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ (entailmentØŒ contradictionØŒ neutral)
- **Ù…Ø«Ø§Ù„:**
  ```
  Premise: A man is walking his dog.
  Hypothesis: The man owns a pet.
  Output: entailment
  ```

#### 3. **Paraphrase Detection**
- **ØªÙˆØ¶ÛŒØ­:** Ø¢ÛŒØ§ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ Ù…Ø¹Ù†Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù†ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŸ
- **Ù…Ø«Ø§Ù„:**
  ```
  Sentence1: The cat is on the mat.
  Sentence2: There's a cat sitting on the rug.
  Output: yes
  ```

#### 4. **Acceptability Judgment**
- **ØªÙˆØ¶ÛŒØ­:** Ø¢ÛŒØ§ Ø¬Ù…Ù„Ù‡ Ø§Ø² Ù„Ø­Ø§Ø¸ Ù†Ø­ÙˆÛŒ Ø¯Ø±Ø³Øª Ø§Ø³ØªØŸ
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: He go to school yesterday.
  Output: unacceptable
  ```

#### 5. **Question Answering (QA)**
- **ØªÙˆØ¶ÛŒØ­:** ÛŒØ§ÙØªÙ† Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³Ø¤Ø§Ù„ Ø§Ø² ÛŒÚ© Ù…ØªÙ†
- **Ù…Ø«Ø§Ù„:**
  ```
  Context: Paris is the capital of France.
  Question: What is the capital of France?
  Output: Paris
  ```

#### 6. **Coreference Resolution**
- **ØªÙˆØ¶ÛŒØ­:** ØªØ´Ø®ÛŒØµ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ùˆ Ø§Ø³Ù… ÛŒØ§ Ø¶Ù…ÛŒØ± Ø¨Ù‡ Ú†Ù‡ Ú†ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
- **Ù…Ø«Ø§Ù„:**
  ```
  John told Mary he would come. â†’ "he" refers to John
  ```

#### 7. **Textual Entailment**
- **ØªÙˆØ¶ÛŒØ­:** Ø¢ÛŒØ§ Ø¬Ù…Ù„Ù‡ Ø§ÙˆÙ„ Ø´Ø§Ù…Ù„ Ø¬Ù…Ù„Ù‡ Ø¯ÙˆÙ… Ø§Ø³ØªØŸ
- **Ù…Ø«Ø§Ù„:**
  ```
  Sentence1: The car is red.
  Sentence2: The car has color.
  Output: yes
  ```

---

### ğŸ”¹ **Ø¨) Token-level Tasks**
#### 1. **Part-of-Speech (POS) Tagging**
- **ØªÙˆØ¶ÛŒØ­:** Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù„Ù…Ø§Øª Ø¨Ø§ Ù†Ù‚Ø´ Ø¯Ø³ØªÙˆØ±ÛŒ (Ø§Ø³Ù…ØŒ ÙØ¹Ù„ØŒ ...)
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: The quick brown fox jumps over the lazy dog.
  Output: DET ADJ ADJ NOUN VERB ADP DET ADJ NOUN
  ```

#### 2. **Named Entity Recognition (NER)**
- **ØªÙˆØ¶ÛŒØ­:** ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ (Ø´Ø®ØµØŒ Ù…Ú©Ø§Ù†ØŒ Ø³Ø§Ø²Ù…Ø§Ù† Ùˆ ...)
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: Google was founded by Larry Page and Sergey Brin.
  Output: [ORG Google] was founded by [PER Larry Page] and [PER Sergey Brin].
  ```

#### 3. **Chunking**
- **ØªÙˆØ¶ÛŒØ­:** ØªÙ‚Ø³ÛŒÙ… Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: The quick brown fox jumps over the lazy dog.
  Output: [NP The quick brown fox] [VP jumps over] [NP the lazy dog]
  ```

---

### ğŸ”¹ **Ø¬) Sequence-to-Sequence Tasks**
#### 1. **Machine Translation (MT)**
- **ØªÙˆØ¶ÛŒØ­:** ØªØ±Ø¬Ù…Ù‡ ÛŒÚ© Ù…ØªÙ† Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø¯ÛŒÚ¯Ø±
- **Ù…Ø«Ø§Ù„:**
  ```
  Input (English): The cat is on the mat.
  Output (French): Le chat est sur le tapis.
  ```

#### 2. **Abstractive Summarization**
- **ØªÙˆØ¶ÛŒØ­:** Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø§ ØªÙˆÙ„ÛŒØ¯ Ø¬Ù…Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: State authorities dispatched emergency crews after a storm hospitalized six people in rural county.
  Output: Six people hospitalized after storm.
  ```

#### 3. **Dialogue Systems**
- **ØªÙˆØ¶ÛŒØ­:** Ù…Ø¯ÛŒØ±ÛŒØª Ú¯ÙØªâ€ŒÙˆÚ¯Ùˆ Ø¨Ø§ Ú©Ø§Ø±Ø¨Ø±
- **Ù…Ø«Ø§Ù„:**
  ```
  User: What's the weather like today?
  Model: It's sunny with a high of 25Â°C.
  ```

#### 4. **Text Simplification**
- **ØªÙˆØ¶ÛŒØ­:** Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© Ø¨Ù‡ØªØ±
- **Ù…Ø«Ø§Ù„:**
  ```
  Input: The phenomenon of climate change is causing global warming.
  Output: Climate change makes Earth warmer.
  ```

#### 5. **Text Generation**
- **ØªÙˆØ¶ÛŒÙ‚:** ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø¬Ø¯ÛŒØ¯ Ø§Ø² Ø±ÙˆÛŒ prompt
- **Ù…Ø«Ø§Ù„:**
  ```
  Prompt: Write a story about space exploration.
  Output: Once upon a time, astronauts discovered a new galaxy...
  ```

---

### ğŸ”¹ **Ø¯) Multi-modal Tasks**
#### 1. **Image Captioning**
- **ØªÙˆØ¶ÛŒØ­:** ØªÙˆØµÛŒÙ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø¬Ù…Ù„Ù‡
- **Ù…Ø«Ø§Ù„:**
  ```
  Image: A woman riding a bike.
  Output: A woman is riding a bicycle outside.
  ```

#### 2. **Visual Question Answering (VQA)**
- **ØªÙˆØ¶ÛŒØ­:** Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³Ø¤Ø§Ù„ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØªØµÙˆÛŒØ±
- **Ù…Ø«Ø§Ù„:**
  ```
  Image: A dog playing with a ball.
  Question: What is the animal doing?
  Output: Playing
  ```

#### 3. **Speech-to-Text / Text-to-Speech**
- **ØªÙˆØ¶ÛŒØ­:** ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ùˆ Ø¨Ø§Ù„Ø¹Ú©Ø³

---

## ğŸ“Š **Û³. Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø±ÙˆÙ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¸Ø§ÛŒÙ NLP**

| Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ | Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ | ØªÙˆØ¶ÛŒØ­ |
|-------------|------------|---------|
| **GLUE Benchmark** | ClassificationØŒ NLIØŒ Similarity | Ø´Ø§Ù…Ù„ 9 ÙˆØ¸ÛŒÙÙ‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ù…Ø«Ù„ SST-2ØŒ MNLIØŒ MRPC |
| **SuperGLUE** | ClassificationØŒ QAØŒ Reasoning | ÙˆØ¸Ø§ÛŒÙ Ø³Ø®Øªâ€ŒØªØ± Ø§Ø² GLUE |
| **SQuAD** | Question Answering | Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ù‡ Ø³Ø¤Ø§Ù„ Ø§Ø² Ù…ØªÙ† |
| **CoNLL-2003** | Named Entity Recognition | ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ |
| **CNN/DM** | Summarization | Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø®Ø¨Ø§Ø± |
| **WMT** | Machine Translation | ØªØ±Ø¬Ù…Ù‡ Ù…Ø§Ø´ÛŒÙ†ÛŒ |
| **BoolQ** | Question Answering | Ø³Ø¤Ø§Ù„Ø§Øª Ø¨Ù„Ù‡/Ø®ÛŒØ± |
| **WiC** | Word-in-Context | Ø¢ÛŒØ§ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø¯Ø± Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ ÛŒÚ©Ø³Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ØŸ |

---

## ğŸ¯ **Û´. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ÙˆØ¸Ø§ÛŒÙ**

| Ù…Ø¯Ù„ | Classification | NLI | QA | Translation | Summarization | Few-shot | Zero-shot |
|-----|----------------|-----|----|-------------|---------------|----------|-----------|
| **BERT** | âœ… Ø¹Ø§Ù„ÛŒ | âœ… Ø¹Ø§Ù„ÛŒ | âœ… Ø¹Ø§Ù„ÛŒ | âŒ | âŒ | âŒ | âŒ |
| **RoBERTa** | âœ… Ø¹Ø§Ù„ÛŒ | âœ… Ø¹Ø§Ù„ÛŒ | âœ… Ø¹Ø§Ù„ÛŒ | âŒ | âŒ | âŒ | âŒ |
| **GPT-3** | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ¨ | âœ… Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ¨ |
| **T5** | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ |
| **BART** | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø¹Ø§Ù„ÛŒ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ |
| **Prompt-based models** | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ | âœ… Ø®ÙˆØ¨ |

---

## ğŸ§ª **Ûµ. ÙˆØ¸Ø§ÛŒÙ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ´ Ø­Ù„ (Prompt-based vs Full FT)**

### Ø§Ù„Ù) **Prompt-based Learning**
- Ø¨Ø¯ÙˆÙ† fine-tuning Ú©Ø§Ù…Ù„
- ØªÙ†Ù‡Ø§ Ø¨Ø§ Ø·Ø±Ø§Ø­ÛŒ Ø¯Ù‚ÛŒÙ‚ prompt Ùˆ label words
- Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:
  - ÙˆØ¸Ø§ÛŒÙ classification (SST-2ØŒ CoLA)
  - NLI (MNLIØŒ RTE)
  - Question Answering (SQuAD)
  - Paraphrase Detection (MRPC)

### Ø¨) **Full Fine-tuning**
- ØªÙ…Ø§Ù… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
- Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:
  - ÙˆØ¸Ø§ÛŒÙ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ ÙØ±Ø§ÙˆØ§Ù†
  - ÙˆØ¸Ø§ÛŒÙ generation (ØªØ±Ø¬Ù…Ù‡ØŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ)
  - ÙˆØ¸Ø§ÛŒÙ token-level (NERØŒ POS)

---

## ğŸ§© **Û¶. Ú†Ø·ÙˆØ± ÛŒÚ© ÙˆØ¸ÛŒÙÙ‡ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Prompt-based ÙØ±Ù…ÙˆÙ„â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†ÛŒÙ…ØŸ**

### Ù…Ø±Ø­Ù„Ù‡ Û±: **ÙØ±Ù…ÙˆÙ„â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¸ÛŒÙÙ‡ Ø¨Ø§ Template**
```
[Sentence] It was [MASK].
```

### Ù…Ø±Ø­Ù„Ù‡ Û²: **Ø§Ù†ØªØ®Ø§Ø¨ Label Words**
```
[MASK] = great â†’ positive  
[MASK] = terrible â†’ negative
```

### Ù…Ø±Ø­Ù„Ù‡ Û³: **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ**
- Ù…Ø¯Ù„ Ø§Ø­ØªÙ…Ø§Ù„ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
- Ú©Ù„Ù…Ù‡ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø± label words Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

---

## ğŸ“ˆ **Û·. Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± ÙˆØ¸Ø§ÛŒÙ Ù…Ø®ØªÙ„Ù (Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ú©Ù… Ùˆ Ø²ÛŒØ§Ø¯)**

### Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ú©Ù… (Few-shot)
| Ø±ÙˆØ´ | SST-2 | CoLA | RTE | MRPC |
|------|-------|------|-----|------|
| **Prompt-based Zero-shot** | 83.6% | 32.0% | 51.3% | 61.9% |
| **Prompt-based Few-shot** | 92.7% | 91.2% | 69.1% | 74.5% |
| **Full Fine-tuning** | 95.0% | 97.0% | 80.9% | 91.4% |

### Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ø²ÛŒØ§Ø¯ (Full Data)
| Ø±ÙˆØ´ | SST-2 | CoLA | RTE | MRPC |
|------|-------|------|-----|------|
| **Prompt-based** | ~85% | ~80% | ~65% | ~70% |
| **Full Fine-tuning** | 95% | 97% | 81% | 91% |

> âš ï¸ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¯Ø± Ø´Ø±Ø§ÛŒØ· **few-shot**ØŒ Prompt-based learning Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ø¯ ÙˆÙ„ÛŒ Ø¯Ø± Ø´Ø±Ø§ÛŒØ· **Ø¯Ø§Ø¯Ù‡ ÙØ±Ø§ÙˆØ§Ù†**ØŒ full fine-tuning Ø¨Ù‡ØªØ± Ø§Ø³Øª.

---

## ğŸ§¬ **Û¸. ÙˆØ¸Ø§ÛŒÙ Ù…Ø®ØµÙˆØµ Ø¨Ø±Ø§ÛŒ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ùˆ Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù…â€ŒÙ…Ù†Ø¨Ø¹**

Ø¯Ø± Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ **ÙØ§Ø±Ø³ÛŒ** Ú©Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡ Ú©Ù… Ø§Ø³ØªØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø¨Ù‡ØªØ±ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ù‡Ø³ØªÙ†Ø¯:

| Ù…Ø¯Ù„ | Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒØŸ | Ø¯Ù‚Øª (Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ú©Ù…) |
|-----|--------------------|-------------------|
| **mBERT** | âœ… Ø¨Ù„Ù‡ | 80â€“85% |
| **XLM-R** | âœ… Ø¨Ù„Ù‡ | 85â€“90% |
| **Prompt-based + XLM-R** | âœ…âœ… Ø¨Ø³ÛŒØ§Ø± Ù…Ù†Ø§Ø³Ø¨ | 88â€“92% |
| **T5** | âœ… Ø¨Ø§ fine-tuning | 85â€“90% |
| **BART** | âœ… Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ | 87â€“91% |
| **GPT (smaller versions)** | âœ… ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† | 80â€“85% |

---

## ğŸ§° **Û¹. Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² ÙØ±Ù…ÙˆÙ„â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¨Ø§ Prompt-based Learning**

### Û±. **Sentiment Analysis**
```
Input: I really liked this movie.
Template: It was [MASK].
Label Words: great / terrible
Output: great
```

### Û². **NLI**
```
Premise: A soccer game with multiple males playing.
Hypothesis: Some men are playing sport.
Template: <S1>?[MASK],<S2>
Label Words: Yes / Maybe / No
Output: Yes
```

### Û³. **Question Answering**
```
Passage: Paris is the capital of France.
Question: What is the capital of France?
Template: Passage: [PASSAGE]. Question: [QUESTION]? Answer: [MASK].
Label Words: Paris
Output: Paris
```

### Û´. **Translation**
```
Input: That is good.
Template: Translate English to German: That is good.
Label Words: Das ist gut
Output: Das ist gut
```

---

## ğŸ“¦ **Û±Û°. ÙˆØ¸Ø§ÛŒÙ Ø®Ø§Øµ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Encoder-Decoder (Ù…Ø«Ù„ T5 Ùˆ BART)**

| ÙˆØ¸ÛŒÙÙ‡ | Template | Ù…Ø«Ø§Ù„ |
|--------|----------|--------|
| **Summarization** | `summarize:` | Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù‚Ø§Ù„Ù‡ |
| **Translation** | `translate English to French:` | ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† |
| **Text Simplification** | `simplify:` | Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ù…Ù„Ù‡ |
| **Paraphrasing** | `paraphrase:` | Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø¬Ù…Ù„Ù‡ |
| **Dialogue Response Generation** | `dialogue:` | Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ú¯ÙØªâ€ŒÙˆÚ¯Ùˆ |
| **Data-to-Text Generation** | `generate text from table` | ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙˆÙ† Ø§Ø² Ø¬Ø¯ÙˆÙ„ |
| **Fill-in-the-blank** | `[CLS]The movie was [MASK].` | Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¬Ø§ÛŒ Ø®Ø§Ù„ÛŒ |
| **Text Correction** | `correct:` | Ø§ØµÙ„Ø§Ø­ Ù…ØªÙ† |
| **Text Style Transfer** | `formalize:` / `informalize:` | ØªØºÛŒÛŒØ± Ø³Ø¨Ú© Ù…ØªÙ† |

---

## ğŸ“‹ **Û±Û±. Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² ÙˆØ¸Ø§ÛŒÙ Ø¯Ø± GLUE Ùˆ SuperGLUE**

| Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ | Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ | ØªÙˆØ¶ÛŒØ­ |
|-------------|------------|--------|
| **SST-2** | Sentiment Analysis | Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ Ù…Ø«Ø¨Øª/Ù…Ù†ÙÛŒ |
| **CoLA** | Acceptability | Ø¯Ø±Ø³ØªÛŒ Ú¯Ø±Ø§Ù…Ø±ÛŒ Ø¬Ù…Ù„Ù‡ |
| **MRPC** | Paraphrase Detection | Ø¢ÛŒØ§ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ Ù…Ø¹Ù†Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù†ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŸ |
| **STS-B** | Sentence Similarity | Ø´Ø¨Ø§Ù‡Øª Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ (Ø¹Ø¯Ø¯ÛŒ Ø¨ÛŒÙ† 1 ØªØ§ 5) |
| **QQP** | Duplicate Questions | Ø¢ÛŒØ§ Ø¯Ùˆ Ø³Ø¤Ø§Ù„ ÛŒÚ©Ø³Ø§Ù† Ù‡Ø³ØªÙ†Ø¯ØŸ |
| **MNLI** | NLI | Ø±Ø§Ø¨Ø·Ù‡ Ù…Ù†Ø·Ù‚ÛŒ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ |
| **RTE** | NLI | Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù†Ø·Ù‚ÛŒ Ø¯Ø± Ù…ØªÙ† Ú©ÙˆØªØ§Ù‡ |
| **WNLI** | Coreference | Ø¢ÛŒØ§ ÛŒÚ© Ø¶Ù…ÛŒØ± Ø¨Ù‡ ÛŒÚ© Ø§Ø³Ù… Ø§Ø´Ø§Ø±Ù‡ Ø¯Ø§Ø±Ø¯ØŸ |

---

## ğŸ§  **Û±Û². Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ**

### âœ… **Ù…Ø²Ø§ÛŒØ§ÛŒ Ø§ØµÙ„ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø¨Ø²Ø±Ú¯**
- **Ø¯Ø§Ù†Ø´ Ø¹Ù…ÙˆÙ…ÛŒ**: Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø§Ù†Ø´ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø² Ø²Ø¨Ø§Ù† Ø¯Ø§Ø±Ù†Ø¯.
- **Ù‚Ø§Ø¨Ù„ÛŒØª generalization**: Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø±ÙˆÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¬Ø¯ÛŒØ¯ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø± Ú©Ù†Ù†Ø¯ (zero-shot).
- **Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ**: Ø¨Ø§ ØªØºÛŒÛŒØ± prompt Ùˆ label wordsØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ ÙˆØ¸Ø§ÛŒÙ Ù…Ø®ØªÙ„Ù Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù†Ø¯.

### âŒ **Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§**
- **Ø·Ø±Ø§Ø­ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ prompt Ùˆ label words**
- **Ø¹Ø¯Ù… Ø«Ø¨Ø§Øª Ø¯Ø± zero-shot (Ø¨Ø³ØªÙ‡ Ø¨Ù‡ template Ùˆ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ)**
- **Ù†ÛŒØ§Ø² Ø¨Ù‡ fine-tuning Ø¯Ø± ÙˆØ¸Ø§ÛŒÙ Ù¾ÛŒÚ†ÛŒØ¯Ù‡**

---

## ğŸ§¾ **Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ**

| Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ | Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ | Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ |
|----------|--------------|----------------|
| **Sentence Classification** | RoBERTaØŒ BERT | Prompt-based ÛŒØ§ Full FT |
| **NERØŒ POS Tagging** | BERTØŒ XLM-R | Token-level FT |
| **Translation** | T5ØŒ BARTØŒ MarianMT | Seq2Seq Fine-tuning |
| **Summarization** | BARTØŒ T5 | Seq2Seq Fine-tuning |
| **Question Answering** | BERTØŒ T5 | Masked LM ÛŒØ§ Seq2Seq |
| **Zero-shot/Few-shot** | GPTØŒ T5ØŒ BART | Prompt-based Tuning |
| **Low-resource languages** | XLM-RØŒ mBERTØŒ T5 | Prompt-based ÛŒØ§ Multilingual FT |

---

Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ **Ú©Ø¯ Ù†Ù…ÙˆÙ†Ù‡** Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙˆØ¸ÛŒÙÙ‡ Ø®Ø§Øµ (Ù…Ø«Ù„ sentiment analysis ÛŒØ§ translation) Ø¨Ø¨ÛŒÙ†ÛŒØ¯ØŒ ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÛŒÚ© **prompt template Ø®ÙˆØ¯Ú©Ø§Ø±** Ø¨Ø³Ø§Ø²ÛŒØ¯ØŒ ÙÙ‚Ø· Ø¨Ú¯Ùˆ!
